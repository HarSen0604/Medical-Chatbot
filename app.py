import os
from PyPDF2 import PdfReader
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain_openai import OpenAI
from flask import Flask, render_template, request, make_response
from weasyprint import HTML

API_KEY_PATH = "openai_key.pem"

def load_API_Key(pem_file):
    """
    Reads an API key from a .pem file.
    Args:
        pem_file (str): Path to the .pem file containing the API key.
    Returns:
        str: The API key as a string.
    """
    with open(pem_file, "r") as file:
        lines = file.readlines()
        # Extract the key between the custom BEGIN/END markers
        key_lines = lines[1:-1]  # Skip the first and last lines
        api_key = "".join(line.strip() for line in key_lines)
        return api_key

def process_pdf(pdf_path):
    """
    This function reads a PDF file and extracts all the text content from it.

    Args:
        pdf_path (str): Path to the PDF file.

    Returns:
        str: The extracted text content from the PDF.
    """
    reader = PdfReader(pdf_path)
    raw_text = ''
    for page in reader.pages:
        text = page.extract_text()
        if text:
            raw_text += text
    return raw_text

os.environ["OPENAI_API_KEY"] = load_API_Key(API_KEY_PATH)

# Initialize Flask app
app = Flask(__name__)

# Initialize Flask routes
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/submit', methods=['POST'])
def submit():
    # Extract form data
    full_name = request.form['full_name']
    age = request.form['age']
    gender = request.form['gender']
    symptoms = request.form['symptoms']
    
    # Formulate final input for processing
    final_input = "The given conversation acts as the \'communicationEnglish\'. By matching those, only return the appropriate list of symptoms and the name of the disease that was found after analysis. If either the input is wrong or the data is insufficient, just tell that \'Data is insufficient\'"
    final_input += symptoms

    # Process the user query and get the answer
    response = process_query(final_input)
    
    # Render template with response
    return render_template('report_form.html', full_name=full_name, age=age, gender=gender, symptoms=response)

@app.route('/convert_to_pdf', methods=['POST'])
def convert_to_pdf():
    # Extract form data
    full_name = request.form['full_name']
    age = request.form['age']
    gender = request.form['gender']
    symptoms = request.form['symptoms']
    
    # Process the symptoms to generate a response
    response = symptoms
    
    # Render PDF template
    rendered_template = render_template('report.html', full_name=full_name, age=age, gender=gender, symptoms=response)
    
    # Convert HTML to PDF
    pdf = HTML(string=rendered_template).write_pdf()
    
    # Save the generated PDF
    with open("report.pdf", "wb") as f:
        f.write(pdf)
    
    # Prepare PDF response
    with open("report.pdf", "rb") as f:
        generated_pdf = f.read()
    
    response = make_response(generated_pdf)
    response.headers['Content-Type'] = 'application/pdf'
    response.headers['Content-Disposition'] = f'attachment; filename="{full_name}_report.pdf"'
    
    return response

# Main function to process user query
def process_query(query):
    """
    This function takes a user query, searches for similar text chunks in the FAISS index,
    and then uses the question answering model to answer the query based on those relevant chunks.

    Args:
        query (str): The user's question.

    Returns:
        str: The answer generated by the question answering model.
    """
    # Use the QA chain to retrieve relevant information and answer the query
    result = qa_chain.run(query)
    return result

if __name__ == '__main__':
    # Directory containing the PDF files
    data_dir = "./data"

    # Variable to store all extracted text
    final_text = ''

    # Iterate through all files in the data directory
    for filename in os.listdir(data_dir):
        if filename.endswith(".pdf"):
            full_path = os.path.join(data_dir, filename)
            # Call process_pdf to extract text from each PDF
            final_text += process_pdf(full_path)

    # Split the extracted text into smaller chunks for processing
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1500,
        chunk_overlap=200,
        length_function=len,
    )
    texts = text_splitter.split_text(final_text)

    # Initialize OpenAI embeddings for creating vector representations of text
    embeddings = OpenAIEmbeddings()

    # Create FAISS index to efficiently search similar text chunks
    docsearch = FAISS.from_texts(texts, embeddings)

    # Create a retrieval-based QA chain
    retriever = docsearch.as_retriever()
    qa_chain = RetrievalQA.from_chain_type(
        llm=OpenAI(),
        retriever=retriever,
        chain_type="stuff"  # Use appropriate chain type if needed
    )

    # Run Flask app
    print("Starting Flask app. Press Ctrl+C to stop.")
    app.run(debug=True)